{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_PATH = '../UrbanSound8K/metadata/UrbanSound8K.csv'\n",
    "AUDIO_BASE_PATH = '../UrbanSound8K/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchaudio.transforms import Spectrogram, MelSpectrogram, TimeStretch, AmplitudeToDB\n",
    "from torch.distributions import Uniform\n",
    "\n",
    "from helper_classes import _num_stft_bins, RandomTimeStretch, SpecNormalization, MelspectrogramStretch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import load_fold_paths\n",
    "from helper_classes import AudioDataset, TrainingHistory\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from graph_utils import print_metrics, plot_confusion_matrix, plot_fold_accuracies, plot_all_metrics_across_folds, print_cross_validation_results\n",
    "from utils import compute_metrics, cleanup\n",
    "from CNN import AudioCNN, LazyAudioCNNDataset, collate_fn_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_audio_cnn_cross_validation(\n",
    "    data_cache_dir,\n",
    "    config,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    lr=0.001,\n",
    "    device=None,\n",
    "    num_classes=10\n",
    "):\n",
    "    \"\"\"\n",
    "    10-Fold Cross-Validation Pipeline for UrbanSound8K\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Initial GPU memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "    \n",
    "    train_paths, train_labels, test_paths, test_labels = load_fold_paths(data_cache_dir=data_cache_dir)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "    save_dir = f\"../saved_cv/{timestamp}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    print(f\"Save directory: {save_dir}\")\n",
    "    \n",
    "    with open(os.path.join(save_dir, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    fold_results = []\n",
    "    all_fold_accuracies = []\n",
    "    cumulative_confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"10-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Scheme: 1 fold test, 1 fold validation, 8 folds training\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for test_fold in range(1, 11):\n",
    "        val_fold = (test_fold % 10) + 1\n",
    "        train_folds = [f for f in range(1, 11) if f != test_fold and f != val_fold]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"FOLD {test_fold}/10\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Test fold: {test_fold}\")\n",
    "        print(f\"Validation fold: {val_fold}\")\n",
    "        print(f\"Training folds: {train_folds}\")\n",
    "        \n",
    "        fold_dir = os.path.join(save_dir, f'fold_{test_fold}')\n",
    "        os.makedirs(fold_dir, exist_ok=True)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 1: Loading Data from Cache\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        X_train = sum((train_paths[f] for f in train_folds), [])\n",
    "        y_train = sum((train_labels[f] for f in train_folds), [])\n",
    "\n",
    "        X_val = test_paths[val_fold]\n",
    "        y_val = test_labels[val_fold]\n",
    "\n",
    "        X_test = test_paths[test_fold]\n",
    "        y_test = test_labels[test_fold]\n",
    "\n",
    "        train_dataset = LazyAudioCNNDataset(X_train, y_train)\n",
    "        val_dataset   = LazyAudioCNNDataset(X_val, y_val)\n",
    "        test_dataset  = LazyAudioCNNDataset(X_test, y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn_cnn)\n",
    "        val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn_cnn)\n",
    "        test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn_cnn)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 2: Creating Model\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        model = AudioCNN(num_classes=num_classes, config=config)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU memory after model creation: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 3: Training Model\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
    "                                    betas = (config.get('betas')[0],\n",
    "                                    config.get('betas')[1]),\n",
    "                                    eps = config.get('eps'),\n",
    "                                    weight_decay=config.get('weight_decay'))\n",
    "        history = TrainingHistory()\n",
    "        \n",
    "        best_val_loss, best_val_acc = AudioCNN.train(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_fold=test_fold,\n",
    "            history=history,\n",
    "            config=config,\n",
    "            fold_dir=fold_dir,\n",
    "            epochs=epochs,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 4: Testing on Held-Out Fold\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        checkpoint = torch.load(os.path.join(fold_dir, 'best_model.pth'))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        avg_test_loss, test_acc, all_predictions, all_targets = AudioCNN.test(model, criterion, test_loader, device)\n",
    "        \n",
    "        print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "        \n",
    "        test_metrics = compute_metrics(all_predictions, all_targets, num_classes)\n",
    "        print_metrics(test_metrics, prefix=\"Test \")\n",
    "        \n",
    "        fold_confusion_matrix = confusion_matrix(all_targets, all_predictions, labels=range(num_classes))\n",
    "        cumulative_confusion_matrix += fold_confusion_matrix\n",
    "        \n",
    "        fold_result = {\n",
    "            'fold': test_fold,\n",
    "            'test_fold': test_fold,\n",
    "            'val_fold': val_fold,\n",
    "            'train_folds': train_folds,\n",
    "            'test_loss': avg_test_loss,\n",
    "            'test_accuracy': test_metrics['accuracy'],\n",
    "            'test_precision_macro': test_metrics['precision_macro'],\n",
    "            'test_precision_weighted': test_metrics['precision_weighted'],\n",
    "            'test_recall_macro': test_metrics['recall_macro'],\n",
    "            'test_recall_weighted': test_metrics['recall_weighted'],\n",
    "            'test_f1_macro': test_metrics['f1_macro'],\n",
    "            'test_f1_weighted': test_metrics['f1_weighted'],\n",
    "            'test_precision_per_class': test_metrics['precision_per_class'],\n",
    "            'test_recall_per_class': test_metrics['recall_per_class'],\n",
    "            'test_f1_per_class': test_metrics['f1_per_class'],\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'confusion_matrix': fold_confusion_matrix.tolist()\n",
    "        }\n",
    "        fold_results.append(fold_result)\n",
    "        all_fold_accuracies.append(test_acc)\n",
    "        \n",
    "        with open(os.path.join(fold_dir, 'fold_results.json'), 'w') as f:\n",
    "            json.dump(fold_result, f, indent=2)\n",
    "        \n",
    "        class_names = [f'Class_{i}' for i in range(num_classes)]\n",
    "        report = classification_report(all_targets, all_predictions, \n",
    "                                      target_names=class_names, \n",
    "                                      digits=4)\n",
    "        with open(os.path.join(fold_dir, 'classification_report.txt'), 'w') as f:\n",
    "            f.write(f\"Classification Report - Fold {test_fold}\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(report)\n",
    "        \n",
    "        history.save(os.path.join(fold_dir, 'history.json'))\n",
    "        history.plot(save_path=os.path.join(fold_dir, 'training_curves.png'))\n",
    "        \n",
    "        plot_confusion_matrix(\n",
    "            fold_confusion_matrix,\n",
    "            save_path=os.path.join(fold_dir, 'confusion_matrix.png'),\n",
    "            title=f'Confusion Matrix - Fold {test_fold}'\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFold {test_fold} completed!\")\n",
    "        print(f\"Results saved to: {fold_dir}\")\n",
    "        \n",
    "        cleanup(train_loader, val_loader, test_loader,\n",
    "            train_dataset, val_dataset, test_dataset,\n",
    "            model, optimizer, criterion, history,\n",
    "            all_predictions, all_targets,\n",
    "            checkpoint)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    return print_cross_validation_results(fold_results, save_dir)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from utils import read_config\n",
    "\n",
    "config = read_config(\"../config/cnn.json\")\n",
    "\n",
    "base_dir = '../data_cache'\n",
    "folders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
    "\n",
    "folder_dates = []\n",
    "for folder in folders:\n",
    "    try:\n",
    "        folder_date = datetime.strptime(folder, '%m%d_%H%M%S')\n",
    "        folder_dates.append((folder_date, folder))\n",
    "    except ValueError:\n",
    "        print(f\"Folder name '{folder}' does not match expected format.\")\n",
    "\n",
    "if folder_dates:\n",
    "    most_recent_folder = max(folder_dates, key=lambda x: x[0])[1]\n",
    "    data_cache_dir = os.path.join(base_dir, most_recent_folder)\n",
    "    print(f\"Most recent folder: {data_cache_dir}\")\n",
    "\n",
    "else:\n",
    "    print(\"No valid folders found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_audio_cnn_cross_validation(\n",
    "    data_cache_dir=data_cache_dir,\n",
    "    config=config,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    lr=0.01,\n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "print(f\"Model saved to: {results['save_dir']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
