{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_cnn(batch):\n",
    "    \"\"\"\n",
    "    Input: List of (audio, label) tuples from dataset\n",
    "    Output: Padded batch ready for CNN\n",
    "    \"\"\"\n",
    "    audios, labels = zip(*batch)  # Separate audio and labels\n",
    "    \n",
    "    # 1. Get actual lengths of each audio\n",
    "    lengths = torch.LongTensor([len(a) for a in audios])\n",
    "    # Example: [44100, 88200, 22050]\n",
    "    \n",
    "    # 2. Pad all audios to the same length (longest in batch)\n",
    "    padded_audio = nn.utils.rnn.pad_sequence(audios, batch_first=True)\n",
    "    # Example shape: (3, 88200) - all padded to longest (88200)\n",
    "    \n",
    "    # 3. Stack labels\n",
    "    labels = torch.stack(labels)\n",
    "    \n",
    "    return padded_audio, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, classes=10, config={}):\n",
    "        super(AudioCNN, self).__init__()\n",
    "        \n",
    "        self.num_classes = classes\n",
    "        self.config = config\n",
    "\n",
    "        self.net = nn.ModuleDict() \n",
    "\n",
    "        self.input_channels = 1\n",
    "\n",
    "        # Spectrogram transform\n",
    "        self.spec = MelspectrogramStretch(\n",
    "            hop_length=config.get('hop_length', None),\n",
    "            num_mels=config.get('num_mels', 128),\n",
    "            fft_length=config.get('fft_length', 2048),\n",
    "            norm=config.get('norm', 'whiten'),\n",
    "            stretch_param=config.get('stretch_param', [0.4, 0.4])\n",
    "        )\n",
    "\n",
    "        # CNN parameters\n",
    "        self.hidden_channels = self.config.get('hidden_channels', 32)\n",
    "        self.num_layers = self.config.get('num_layers', 3)\n",
    "        self.cnn_dropout = self.config.get('cnn_dropout', 0.3)\n",
    "\n",
    "        # self.final_flatten_size = self.config.get('final_flatten_size')\n",
    "        self.padding = self.config.get('padding', 0)\n",
    "\n",
    "\n",
    "        # Build network from cfg\n",
    "        # Input shape: [channel, frequency, time]\n",
    "        self.net['convs'] = nn.Sequential(\n",
    "            # Layer 1: Input channel 1 -> Hidden channels\n",
    "            nn.Conv2d(self.input_channels, self.hidden_channels, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(self.hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            \n",
    "            # Layer 2 to n_layers+1: All take hidden_channels -> Hidden channels\n",
    "            *[nn.Sequential(\n",
    "                nn.Conv2d(self.hidden_channels, self.hidden_channels, kernel_size=3, padding=0),\n",
    "                nn.BatchNorm2d(self.hidden_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            ) for _ in range(self.num_layers)],\n",
    "            \n",
    "            # Final Pooling\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)), \n",
    "        )\n",
    "\n",
    "        # Calculate the flattened size after convolutions\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, self.input_channels, self.spec.n_mels, 400)\n",
    "            dummy_output = self.net['convs'](dummy_input)\n",
    "            self.final_flatten_size = dummy_output.view(1, -1).size(1)\n",
    "        \n",
    "        # --- 3. Classification Head ---\n",
    "        # The first Linear layer size must match the output size of the CNN body after flattening.\n",
    "        # final_flatten_size needs to be calculated dynamically or estimated. \n",
    "        # For simplicity, we use a placeholder and a dense head.\n",
    "        self.net['dense'] = nn.Sequential(\n",
    "            nn.Linear(self.final_flatten_size, self.hidden_channels), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.cnn_dropout),\n",
    "            nn.Linear(self.hidden_channels, self.num_classes) # Final output layer for classification\n",
    "        )\n",
    "\n",
    "    def forward(self, audio, lengths):\n",
    "        \n",
    "        # Add channel dimension: (batch, time) -> (batch, 1, time)\n",
    "        if audio.dim() == 2:\n",
    "            audio = audio.unsqueeze(1)\n",
    "\n",
    "        audio = audio.float()\n",
    "\n",
    "        # Compute mel spectrogram: (batch, 1, time) -> (batch, 1, freq, time)\n",
    "        x, lengths = self.spec(audio, lengths)\n",
    "\n",
    "        # CNN processing: (batch, channel, freq, time)\n",
    "        x = self.net['convs'](x)\n",
    "\n",
    "        # Flatten: (batch, time*freq*channel)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Classification: (batch, classes)\n",
    "        x = self.net['dense'](x)\n",
    "\n",
    "        # Return raw logits for Cross Entropy Loss\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def train(model, train_loader, val_loader, test_fold, history, config, fold_dir, epochs: int, optimizer, criterion,  device):\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_val_acc = 0.0\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            # TRAIN\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            train_pbar = tqdm(train_loader, desc='Training', leave=False)\n",
    "            for audio, lengths, labels in train_pbar:\n",
    "\n",
    "                audio = audio.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(audio, lengths)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Track metrics\n",
    "                train_loss += loss.item()\n",
    "                pred = outputs.argmax(dim=1)\n",
    "                train_correct += (pred == labels).sum().item()\n",
    "                train_total += labels.size(0)\n",
    "                \n",
    "                train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            train_acc = train_correct / train_total\n",
    "            \n",
    "            # VALIDATE\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                val_pbar = tqdm(val_loader, desc='Validation', leave=False)\n",
    "                for audio, lengths, labels in val_pbar:\n",
    "                    audio = audio.to(device)\n",
    "                    lengths = lengths.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    outputs = model(audio, lengths)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    pred = outputs.argmax(dim=1)\n",
    "                    val_correct += (pred == labels).sum().item()\n",
    "                    val_total += labels.size(0)\n",
    "                    \n",
    "                    val_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            val_acc = val_correct / val_total\n",
    "            \n",
    "            # Log metrics\n",
    "            history.add('train_loss', avg_train_loss)\n",
    "            history.add('train_accuracy', train_acc)\n",
    "            history.add('val_loss', avg_val_loss)\n",
    "            history.add('val_accuracy', val_acc)\n",
    "            \n",
    "            print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "            print(f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            \n",
    "            # Save best model for this fold\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_val_acc = val_acc\n",
    "                torch.save({\n",
    "                    'fold': test_fold,\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_loss': best_val_loss,\n",
    "                    'val_acc': best_val_acc,\n",
    "                    'config': config\n",
    "                }, os.path.join(fold_dir, 'best_model.pth'))\n",
    "                print(f\"✓ Best model saved (Val Loss: {best_val_loss:.4f})\")\n",
    "\n",
    "        return best_val_loss, best_val_acc\n",
    "\n",
    "class AudioCNNDataset(Dataset):\n",
    "    def __init__(self, audio_data, labels):\n",
    "        self.audio_data = audio_data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.audio_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio = self.audio_data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if not isinstance(audio, torch.Tensor):\n",
    "            audio = torch.FloatTensor(audio)\n",
    "        if audio.dim() > 1:\n",
    "            audio = audio.squeeze()\n",
    "        \n",
    "        if not isinstance(label, torch.Tensor):\n",
    "            label = torch.LongTensor([label])[0]\n",
    "        \n",
    "        return audio, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_audio_cnn_cross_validation(\n",
    "    df,\n",
    "    audio_base_path,\n",
    "    config,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    lr=0.001,\n",
    "    device=None,\n",
    "    num_classes=10\n",
    "):\n",
    "    \"\"\"\n",
    "    10-Fold Cross-Validation Pipeline for UrbanSound8K\n",
    "    \n",
    "    In each iteration:\n",
    "    - 1 fold for test\n",
    "    - 1 fold for validation  \n",
    "    - 8 folds for training\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        UrbanSound8K metadata (must have 'fold' column)\n",
    "    audio_base_path : str\n",
    "        Path to audio files\n",
    "    config : dict\n",
    "        Model configuration\n",
    "    epochs : int\n",
    "        Training epochs per fold\n",
    "    batch_size : int\n",
    "        Batch size\n",
    "    lr : float\n",
    "        Learning rate\n",
    "    device : str\n",
    "        'cuda' or 'cpu'\n",
    "    num_classes : int\n",
    "        Number of classes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with:\n",
    "        - fold_results: list of results per fold\n",
    "        - cumulative_confusion_matrix: confusion matrix summed over all folds\n",
    "        - mean_accuracy: mean accuracy over 10 folds\n",
    "        - std_accuracy: standard deviation of accuracy\n",
    "        - All precision, recall, F1 metrics (mean and std)\n",
    "        - save_dir: directory where results were saved\n",
    "    \"\"\"\n",
    "    \n",
    "    # device = torch.device(\"cuda:1\")  # RX 6650M - the dedicated GPU\n",
    "    device = torch.device(\"cpu\")  \n",
    "\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create save directory\n",
    "    timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "    save_dir = f\"saved_cv/{timestamp}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    print(f\"Save directory: {save_dir}\")\n",
    "    \n",
    "    # Save configuration\n",
    "    with open(os.path.join(save_dir, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Initialize results storage\n",
    "    fold_results = []\n",
    "    all_fold_accuracies = []\n",
    "    cumulative_confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"10-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Scheme: 1 fold test, 1 fold validation, 8 folds training\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Iterate through 10 folds\n",
    "    for test_fold in range(1, 11):\n",
    "        # Determine validation fold (next fold, wrapping around)\n",
    "        val_fold = (test_fold % 10) + 1\n",
    "        \n",
    "        # Training folds are all others\n",
    "        train_folds = [f for f in range(1, 11) if f != test_fold and f != val_fold]\n",
    "        \n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"FOLD {test_fold}/10\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        print(f\"Test fold: {test_fold}\")\n",
    "        print(f\"Validation fold: {val_fold}\")\n",
    "        print(f\"Training folds: {train_folds}\")\n",
    "        \n",
    "        # Create fold-specific save directory\n",
    "        fold_dir = os.path.join(save_dir, f'fold_{test_fold}')\n",
    "        os.makedirs(fold_dir, exist_ok=True)\n",
    "        \n",
    "        # ============================================\n",
    "        # STEP 1: PREPARE DATA FOR THIS FOLD\n",
    "        # ============================================\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 1: Preparing Data\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Split dataframe by folds\n",
    "        train_df = df[df['fold'].isin(train_folds)]\n",
    "        val_df = df[df['fold'] == val_fold]\n",
    "        test_df = df[df['fold'] == test_fold]\n",
    "        \n",
    "        print(f\"Train samples: {len(train_df)}\")\n",
    "        print(f\"Val samples: {len(val_df)}\")\n",
    "        print(f\"Test samples: {len(test_df)}\")\n",
    "        \n",
    "        # Preprocess data\n",
    "        print(\"Preprocessing training data...\")\n",
    "        train_data = preprocess_dataset(\n",
    "            train_df, audio_base_path,\n",
    "            mode='train',\n",
    "            channel_mode='mono',\n",
    "            sr=config.get('sample_rate', 22050),\n",
    "            noise_prob=0.5,\n",
    "            crop_prob=0.5,\n",
    "            augment_prob=0.5\n",
    "        )\n",
    "        \n",
    "        print(\"Preprocessing validation data...\")\n",
    "        val_data = preprocess_dataset(\n",
    "            val_df, audio_base_path,\n",
    "            mode='val',\n",
    "            channel_mode='mono',\n",
    "            sr=config.get('sample_rate', 22050)\n",
    "        )\n",
    "        \n",
    "        print(\"Preprocessing test data...\")\n",
    "        test_data = preprocess_dataset(\n",
    "            test_df, audio_base_path,\n",
    "            mode='val',\n",
    "            channel_mode='mono',\n",
    "            sr=config.get('sample_rate', 22050)\n",
    "        )\n",
    "        \n",
    "        # Create datasets and loaders\n",
    "        train_dataset = AudioCNNDataset(train_data['audio'], train_data['labels'])\n",
    "        val_dataset = AudioCNNDataset(val_data['audio'], val_data['labels'])\n",
    "        test_dataset = AudioCNNDataset(test_data['audio'], test_data['labels'])\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True,\n",
    "            collate_fn=collate_fn_cnn, num_workers=0\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, batch_size=batch_size, shuffle=False,\n",
    "            collate_fn=collate_fn_cnn, num_workers=0\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=batch_size, shuffle=False,\n",
    "            collate_fn=collate_fn_cnn, num_workers=0\n",
    "        )\n",
    "        \n",
    "        # ============================================\n",
    "        # STEP 2: CREATE MODEL\n",
    "        # ============================================\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 2: Creating Model\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        model = AudioCNN(classes=num_classes, config=config)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        \n",
    "        # ============================================\n",
    "        # STEP 3: TRAIN MODEL\n",
    "        # ============================================\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 3: Training Model\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        history = TrainingHistory()\n",
    "        \n",
    "        best_val_loss, best_val_acc = AudioCNN.train(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_fold=test_fold,\n",
    "            history=history,\n",
    "            config=config,\n",
    "            fold_dir=fold_dir,\n",
    "            epochs=epochs,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            device=device\n",
    "        )\n",
    "                \n",
    "        \n",
    "        # ============================================\n",
    "        # STEP 4: TEST ON HELD-OUT FOLD\n",
    "        # ============================================\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 4: Testing on Held-Out Fold\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Load best model for this fold\n",
    "        checkpoint = torch.load(os.path.join(fold_dir, 'best_model.pth'))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        \n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_pbar = tqdm(test_loader, desc='Testing')\n",
    "            for audio, lengths, labels in test_pbar:\n",
    "                audio = audio.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(audio, lengths)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                pred = outputs.argmax(dim=1)\n",
    "                test_correct += (pred == labels).sum().item()\n",
    "                test_total += labels.size(0)\n",
    "                \n",
    "                all_predictions.extend(pred.cpu().numpy())\n",
    "                all_targets.extend(labels.cpu().numpy())\n",
    "                \n",
    "                test_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        test_acc = test_correct / test_total\n",
    "        \n",
    "        print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "        \n",
    "        # Compute all metrics for this fold\n",
    "        test_metrics = compute_metrics(all_predictions, all_targets, num_classes)\n",
    "        print_metrics(test_metrics, prefix=\"Test \")\n",
    "        \n",
    "        # Compute confusion matrix for this fold\n",
    "        fold_confusion_matrix = confusion_matrix(all_targets, all_predictions, labels=range(num_classes))\n",
    "        \n",
    "        # Add to cumulative confusion matrix\n",
    "        cumulative_confusion_matrix += fold_confusion_matrix\n",
    "        \n",
    "        # Store results with all metrics\n",
    "        fold_result = {\n",
    "            'fold': test_fold,\n",
    "            'test_fold': test_fold,\n",
    "            'val_fold': val_fold,\n",
    "            'train_folds': train_folds,\n",
    "            'test_loss': avg_test_loss,\n",
    "            'test_accuracy': test_metrics['accuracy'],\n",
    "            'test_precision_macro': test_metrics['precision_macro'],\n",
    "            'test_precision_weighted': test_metrics['precision_weighted'],\n",
    "            'test_recall_macro': test_metrics['recall_macro'],\n",
    "            'test_recall_weighted': test_metrics['recall_weighted'],\n",
    "            'test_f1_macro': test_metrics['f1_macro'],\n",
    "            'test_f1_weighted': test_metrics['f1_weighted'],\n",
    "            'test_precision_per_class': test_metrics['precision_per_class'],\n",
    "            'test_recall_per_class': test_metrics['recall_per_class'],\n",
    "            'test_f1_per_class': test_metrics['f1_per_class'],\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'confusion_matrix': fold_confusion_matrix.tolist()\n",
    "        }\n",
    "        fold_results.append(fold_result)\n",
    "        all_fold_accuracies.append(test_acc)\n",
    "        \n",
    "        # Save fold results\n",
    "        with open(os.path.join(fold_dir, 'fold_results.json'), 'w') as f:\n",
    "            json.dump(fold_result, f, indent=2)\n",
    "        \n",
    "        # Save classification report\n",
    "        class_names = [f'Class_{i}' for i in range(num_classes)]\n",
    "        report = classification_report(all_targets, all_predictions, \n",
    "                                      target_names=class_names, \n",
    "                                      digits=4)\n",
    "        with open(os.path.join(fold_dir, 'classification_report.txt'), 'w') as f:\n",
    "            f.write(f\"Classification Report - Fold {test_fold}\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(report)\n",
    "        \n",
    "        # Save history and plot\n",
    "        history.save(os.path.join(fold_dir, 'history.json'))\n",
    "        history.plot(save_path=os.path.join(fold_dir, 'training_curves.png'))\n",
    "        \n",
    "        # Plot confusion matrix for this fold\n",
    "        plot_confusion_matrix(\n",
    "            fold_confusion_matrix,\n",
    "            save_path=os.path.join(fold_dir, 'confusion_matrix.png'),\n",
    "            title=f'Confusion Matrix - Fold {test_fold}'\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFold {test_fold} completed!\")\n",
    "        print(f\"Results saved to: {fold_dir}\")\n",
    "        \n",
    "        del train_data, val_data, test_data\n",
    "        del train_dataset, val_dataset, test_dataset\n",
    "        del train_loader, val_loader, test_loader\n",
    "\n",
    "        del model\n",
    "        del optimizer\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        plt.close('all')\n",
    "    \n",
    "    # ============================================\n",
    "    # FINAL RESULTS ACROSS ALL FOLDS\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Compute aggregate metrics\n",
    "    mean_accuracy = np.mean([r['test_accuracy'] for r in fold_results])\n",
    "    std_accuracy = np.std([r['test_accuracy'] for r in fold_results])\n",
    "    \n",
    "    mean_precision_macro = np.mean([r['test_precision_macro'] for r in fold_results])\n",
    "    std_precision_macro = np.std([r['test_precision_macro'] for r in fold_results])\n",
    "    \n",
    "    mean_recall_macro = np.mean([r['test_recall_macro'] for r in fold_results])\n",
    "    std_recall_macro = np.std([r['test_recall_macro'] for r in fold_results])\n",
    "    \n",
    "    mean_f1_macro = np.mean([r['test_f1_macro'] for r in fold_results])\n",
    "    std_f1_macro = np.std([r['test_f1_macro'] for r in fold_results])\n",
    "    \n",
    "    mean_precision_weighted = np.mean([r['test_precision_weighted'] for r in fold_results])\n",
    "    std_precision_weighted = np.std([r['test_precision_weighted'] for r in fold_results])\n",
    "    \n",
    "    mean_recall_weighted = np.mean([r['test_recall_weighted'] for r in fold_results])\n",
    "    std_recall_weighted = np.std([r['test_recall_weighted'] for r in fold_results])\n",
    "    \n",
    "    mean_f1_weighted = np.mean([r['test_f1_weighted'] for r in fold_results])\n",
    "    std_f1_weighted = np.std([r['test_f1_weighted'] for r in fold_results])\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nMetrics per fold:\")\n",
    "    print(f\"{'Fold':<6} {'Acc':<8} {'Prec(M)':<10} {'Rec(M)':<10} {'F1(M)':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, result in enumerate(fold_results, 1):\n",
    "        print(f\"{i:<6} {result['test_accuracy']:<8.4f} \"\n",
    "              f\"{result['test_precision_macro']:<10.4f} \"\n",
    "              f\"{result['test_recall_macro']:<10.4f} \"\n",
    "              f\"{result['test_f1_macro']:<10.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AGGREGATE RESULTS (Mean ± Std)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Accuracy:              {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    print(f\"Precision (macro):     {mean_precision_macro:.4f} ± {std_precision_macro:.4f}\")\n",
    "    print(f\"Recall (macro):        {mean_recall_macro:.4f} ± {std_recall_macro:.4f}\")\n",
    "    print(f\"F1-Score (macro):      {mean_f1_macro:.4f} ± {std_f1_macro:.4f}\")\n",
    "    print(f\"Precision (weighted):  {mean_precision_weighted:.4f} ± {std_precision_weighted:.4f}\")\n",
    "    print(f\"Recall (weighted):     {mean_recall_weighted:.4f} ± {std_recall_weighted:.4f}\")\n",
    "    print(f\"F1-Score (weighted):   {mean_f1_weighted:.4f} ± {std_f1_weighted:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Plot cumulative confusion matrix\n",
    "    plot_confusion_matrix(\n",
    "        cumulative_confusion_matrix,\n",
    "        save_path=os.path.join(save_dir, 'cumulative_confusion_matrix.png'),\n",
    "        title='Cumulative Confusion Matrix (10 Folds)',\n",
    "        normalize=False\n",
    "    )\n",
    "    \n",
    "    # Also plot normalized version\n",
    "    plot_confusion_matrix(\n",
    "        cumulative_confusion_matrix,\n",
    "        save_path=os.path.join(save_dir, 'cumulative_confusion_matrix_normalized.png'),\n",
    "        title='Cumulative Confusion Matrix (Normalized)',\n",
    "        normalize=True\n",
    "    )\n",
    "    \n",
    "    # Save final summary with all metrics\n",
    "    final_results = {\n",
    "        'fold_results': fold_results,\n",
    "        'mean_accuracy': float(mean_accuracy),\n",
    "        'std_accuracy': float(std_accuracy),\n",
    "        'mean_precision_macro': float(mean_precision_macro),\n",
    "        'std_precision_macro': float(std_precision_macro),\n",
    "        'mean_recall_macro': float(mean_recall_macro),\n",
    "        'std_recall_macro': float(std_recall_macro),\n",
    "        'mean_f1_macro': float(mean_f1_macro),\n",
    "        'std_f1_macro': float(std_f1_macro),\n",
    "        'mean_precision_weighted': float(mean_precision_weighted),\n",
    "        'std_precision_weighted': float(std_precision_weighted),\n",
    "        'mean_recall_weighted': float(mean_recall_weighted),\n",
    "        'std_recall_weighted': float(std_recall_weighted),\n",
    "        'mean_f1_weighted': float(mean_f1_weighted),\n",
    "        'std_f1_weighted': float(std_f1_weighted),\n",
    "        'all_fold_accuracies': [float(a) for a in all_fold_accuracies],\n",
    "        'cumulative_confusion_matrix': cumulative_confusion_matrix.tolist(),\n",
    "        'config': config\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(save_dir, 'cross_validation_results.json'), 'w') as f:\n",
    "        json.dump(final_results, f, indent=2)\n",
    "    \n",
    "    # Save summary text report\n",
    "    with open(os.path.join(save_dir, 'summary_report.txt'), 'w') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"10-FOLD CROSS-VALIDATION SUMMARY\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Aggregate Results (Mean ± Std):\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"Accuracy:              {mean_accuracy:.4f} ± {std_accuracy:.4f}\\n\")\n",
    "        f.write(f\"Precision (macro):     {mean_precision_macro:.4f} ± {std_precision_macro:.4f}\\n\")\n",
    "        f.write(f\"Recall (macro):        {mean_recall_macro:.4f} ± {std_recall_macro:.4f}\\n\")\n",
    "        f.write(f\"F1-Score (macro):      {mean_f1_macro:.4f} ± {std_f1_macro:.4f}\\n\")\n",
    "        f.write(f\"Precision (weighted):  {mean_precision_weighted:.4f} ± {std_precision_weighted:.4f}\\n\")\n",
    "        f.write(f\"Recall (weighted):     {mean_recall_weighted:.4f} ± {std_recall_weighted:.4f}\\n\")\n",
    "        f.write(f\"F1-Score (weighted):   {mean_f1_weighted:.4f} ± {std_f1_weighted:.4f}\\n\")\n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Per-Fold Results:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(f\"{'Fold':<6} {'Acc':<8} {'Prec(M)':<10} {'Rec(M)':<10} {'F1(M)':<10}\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        for i, result in enumerate(fold_results, 1):\n",
    "            f.write(f\"{i:<6} {result['test_accuracy']:<8.4f} \"\n",
    "                   f\"{result['test_precision_macro']:<10.4f} \"\n",
    "                   f\"{result['test_recall_macro']:<10.4f} \"\n",
    "                   f\"{result['test_f1_macro']:<10.4f}\\n\")\n",
    "    \n",
    "    # Plot accuracy across folds\n",
    "    plot_fold_accuracies(\n",
    "        all_fold_accuracies,\n",
    "        save_path=os.path.join(save_dir, 'fold_accuracies.png')\n",
    "    )\n",
    "    \n",
    "    # Plot all metrics across folds\n",
    "    plot_all_metrics_across_folds(\n",
    "        fold_results,\n",
    "        save_path=os.path.join(save_dir, 'all_metrics_across_folds.png')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAll results saved to: {save_dir}\")\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'cumulative_confusion_matrix': cumulative_confusion_matrix,\n",
    "        'mean_accuracy': mean_accuracy,\n",
    "        'std_accuracy': std_accuracy,\n",
    "        'mean_precision_macro': mean_precision_macro,\n",
    "        'std_precision_macro': std_precision_macro,\n",
    "        'mean_recall_macro': mean_recall_macro,\n",
    "        'std_recall_macro': std_recall_macro,\n",
    "        'mean_f1_macro': mean_f1_macro,\n",
    "        'std_f1_macro': std_f1_macro,\n",
    "        'save_dir': save_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "\n",
    "model = AudioCNN(classes=10, config=config)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "audio_base_path = 'UrbanSound8K/audio'\n",
    "\n",
    "# Define configuration\n",
    "config = {\n",
    "    # Spectrogram settings\n",
    "    'sample_rate': 22050,\n",
    "    'num_mels': 128,\n",
    "    'fft_length': 2048,\n",
    "    'hop_length': 512,\n",
    "    'norm': 'whiten',\n",
    "    'stretch_param': [0.4, 0.4],\n",
    "    \n",
    "    # CNN settings\n",
    "    'hidden_channels': 32,\n",
    "    'num_layers': 3,\n",
    "    'cnn_dropout': 0.3,\n",
    "}\n",
    "\n",
    "# Run complete pipeline\n",
    "results = train_audio_cnn_cross_validation(\n",
    "    df=df,\n",
    "    audio_base_path=audio_base_path,\n",
    "    config=config,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    lr=0.001,\n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "print(f\"Model saved to: {results['save_dir']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
